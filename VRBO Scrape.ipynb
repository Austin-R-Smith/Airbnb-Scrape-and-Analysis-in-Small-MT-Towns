{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0bc712",
   "metadata": {},
   "source": [
    "# VRBO Scrape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27c8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import requests               \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# imports for Selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46f4f6",
   "metadata": {},
   "source": [
    "Unlike Airbnb, VRBO will show all listings for a given location; there is a button at the bottom of the page that needs to be selected to continue on to subsequent listings.\n",
    "\n",
    "Also unlike Airbnb, VRBO doesn't allow you to be flexible with choosing your visit dates and a pop-up will block the searching by Selenium if I don't select dates. I went far into the future so that the search returned the full number of listings.  \n",
    "\n",
    "Now, the VRBO website doesn't load all of its listings per page automatically. It loads them as someone scrolls through the website. So, I need to tell Selenium to scroll slowly through the website, allowing all of the listings time to load. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b5ca42",
   "metadata": {},
   "source": [
    "## Manual Scrape Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34ec6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gardiner_url = 'https://www.vrbo.com/search/keywords:gardiner-montana-united-states-of-america/arrival:2024-05-13/departure:2024-05-17/minNightlyPrice/0?filterByTotalPrice=false&petIncluded=false&ssr=true&adultsCount=2&childrenCount=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e6b4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Like for Airbnb, I search out the tags that I need to grab for each listing\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(gardiner_url)\n",
    "\n",
    "# this code makes Selenium scroll in increments through the webpage and pause for 1 second to let it load\n",
    "# adjust the time up if your computer is being really slow\n",
    "\n",
    "y = 1000\n",
    "\n",
    "for timer in range(0,50):\n",
    "    driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "    y += 1000  \n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb9af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-2fe2264b47ba>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n"
     ]
    }
   ],
   "source": [
    "next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f5d064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are more pages\n"
     ]
    }
   ],
   "source": [
    "if next_page.is_enabled() :\n",
    "    print(\"there are more pages\")\n",
    "\n",
    "else:\n",
    "    print(\"no more pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd318b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the html\n",
    "\n",
    "html = driver.page_source\n",
    "html_soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inspecting the page, I can see that the information I want for the listings is under the class\n",
    "# \"media-flex__body HitInfo__content\"\n",
    "# (At least for now; this is likely to change with any future website updates!))\n",
    "\n",
    "listings = html_soup.find_all('div', class_ = 'media-flex__body HitInfo__content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10796266",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24fbe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check point \n",
    "# should we 50 listings \n",
    "# (Note: going to figure out pagination later)\n",
    "\n",
    "print(len(listings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by printing just one listing, I can identify which tags I need to grab the listing info\n",
    "\n",
    "print(listings[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557365ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these tags pull the info I want for each listing\n",
    "\n",
    "search_page = {\n",
    "    'name': {'tag': 'h2', 'class': 'HitInfo__headline hover-text'},\n",
    "    'header' : {'tag': 'span','order':0},\n",
    "    'details': {'tag': 'span','order':1},\n",
    "    'n_guests': {'tag': 'span', 'order':2},\n",
    "    'beds': {'tag': 'span', 'order':3}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a046bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will extract all the elements in \"search_page\" above from the html \n",
    "\n",
    "def extract_elements(listing_html, params) :\n",
    "     # Find the right tag\n",
    "    if 'class' in params:\n",
    "        elements_found = listing_html.find_all(params['tag'], params['class'])\n",
    "    else:\n",
    "        elements_found = listing_html.find_all(params['tag'])\n",
    "\n",
    "    # Extract the right element\n",
    "    tag_order = params.get('order', 0)\n",
    "    element = elements_found[tag_order]\n",
    "        \n",
    "    # Get text\n",
    "    if 'get' in params:\n",
    "        output = element.get(params['get'])\n",
    "    else:\n",
    "        output = element.get_text()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a test on the first listing, refine search elements as needed\n",
    "\n",
    "#extract_elements(listings[0], search_page['name'])\n",
    "#extract_elements(listings[0], search_page['header'])\n",
    "#extract_elements(listings[0], search_page['details'])\n",
    "#extract_elements(listings[0], search_page['n_guests'])\n",
    "#extract_elements(listings[0], search_page['beds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3e9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all of the elements with this function\n",
    "\n",
    "def extract_page_features(soup, search_items):\n",
    "    # create a dictionary to hold the features\n",
    "    features_dict = {}\n",
    "    \n",
    "    # go through each item of the search block above and try to find it and put it in dict\n",
    "    for feature in search_items :\n",
    "        try:\n",
    "            features_dict[feature] = extract_elements(soup, search_items[feature])\n",
    "            \n",
    "        # if it doesn't exist, place empty in that field\n",
    "        except:\n",
    "            features_dict[feature] = 'empty'\n",
    "    \n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35386869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function on the first listing\n",
    "\n",
    "extract_page_features(listings[0], search_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d12d6",
   "metadata": {},
   "source": [
    "To get Selenium to advance to the next page of search results, I need to identify the button that goes to the next page. \n",
    "\n",
    "As of the date of this code, it's under the class: \"btn btn-icon ButtonIcon btn-default btn-icon-circle\" with tag \"a\" and then the href item takes one to the next webpage of search results. \n",
    "\n",
    "I can use the \"click\" method to click on the button. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it out ... \n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(gardiner_url)\n",
    "\n",
    "y = 1000\n",
    "\n",
    "for timer in range(0,50):\n",
    "    driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "    y += 1000  \n",
    "    time.sleep(1)\n",
    "\n",
    "next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n",
    "\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13259228",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "916841b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n",
      "<ipython-input-33-f3b824de82a6>:26: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n"
     ]
    }
   ],
   "source": [
    "# putting it all together\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "driver.get(gardiner_url)\n",
    "    \n",
    "# scroll to the bottom of the page, loading the whole thing\n",
    "y = 1000\n",
    "\n",
    "for timer in range(0,50):\n",
    "    driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "    y += 1000  \n",
    "    time.sleep(1)\n",
    "\n",
    "# then parse the html on the page\n",
    "html = driver.page_source\n",
    "html_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "listings = html_soup.find_all('div', class_ = 'media-flex__body HitInfo__content')\n",
    "\n",
    "# then go to the second page \n",
    "next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n",
    "next_page.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8294bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1953c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "\n",
    "for listing in listings:\n",
    "    features = extract_page_features(listing, search_page)\n",
    "    features_list.append(features)\n",
    "    \n",
    "#features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36614109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "737ecb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-8eee24ed44ec>:17: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n"
     ]
    }
   ],
   "source": [
    "# do this four times ... I should be putting this in a function ... but Selenium is scrolling too quickly on subsequent pages\n",
    "\n",
    "y=1000\n",
    "\n",
    "for timer in range(0,50):\n",
    "    driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "    y += 1000  \n",
    "    time.sleep(1)\n",
    "    \n",
    "html = driver.page_source\n",
    "html_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "listings = html_soup.find_all('div', class_ = 'media-flex__body HitInfo__content')\n",
    "\n",
    "# go to the third page\n",
    "next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ff7ef82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a892f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "for listing in listings:\n",
    "    features = extract_page_features(listing, search_page)\n",
    "    features_list.append(features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08b0828f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check \n",
    "len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ece1d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-d95e4cdab85f>:15: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n"
     ]
    }
   ],
   "source": [
    "y = 1000 \n",
    "\n",
    "for timer in range(0,50):\n",
    "    driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "    y += 1000  \n",
    "    time.sleep(1)\n",
    "    \n",
    "html = driver.page_source\n",
    "html_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "listings = html_soup.find_all('div', class_ = 'media-flex__body HitInfo__content')\n",
    "\n",
    "# go to the fourth page\n",
    "next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df2a5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "for listing in listings:\n",
    "    features = extract_page_features(listing, search_page)\n",
    "    features_list.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2ffe3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bca34ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1000\n",
    "\n",
    "for timer in range(0,50):\n",
    "    driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "    y += 1000  \n",
    "    time.sleep(1)\n",
    "    \n",
    "html = driver.page_source\n",
    "html_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "listings = html_soup.find_all('div', class_ = 'media-flex__body HitInfo__content')\n",
    "\n",
    "# all done\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9683f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for listing in listings:\n",
    "    features = extract_page_features(listing, search_page)\n",
    "    features_list.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e330f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a csv\n",
    "\n",
    "gardiner_vrbo_scrape = pd.DataFrame(features_list)\n",
    "gardiner_vrbo_scrape.to_csv('gardiner_vrbo_lists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f4734",
   "metadata": {},
   "source": [
    "## Programmatic Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369bca8d",
   "metadata": {},
   "source": [
    "The Gardiner scrape was a manual process. Here, I try to create a function to make the scrape more programmatic. \n",
    "\n",
    "I need to tell the function to run as long as the button that takes us to the next page isn't disabled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1565d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION 1\n",
    "# didn't work ... \n",
    "\n",
    "def extract_page_listings(search_page) :\n",
    "    \n",
    "    # navigate to the first page\n",
    "    driver.get(search_page)\n",
    "    \n",
    "    # we need to scroll through the page first so that the button can be \"seen\" by Selenium \n",
    "    y = 1000\n",
    "\n",
    "    for timer in range(0,50) :\n",
    "        driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "        y += 1000\n",
    "        time.sleep(1)\n",
    "        \n",
    "    next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n",
    "\n",
    "    while True:\n",
    "        # on the last page of the search results, the button has a note ahead of \"aria-label\" that indicates it's \"disabled\"       \n",
    "        if next_page.is_enabled(): \n",
    "        \n",
    "            # parse the html on the page\n",
    "            html = driver.page_source\n",
    "            html_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            # grab the listings\n",
    "            listings = html_soup.find_all('div', class_ = 'media-flex__body HitInfo__content')\n",
    "\n",
    "            # extract the features of each listing\n",
    "            features_list = []\n",
    "            for listing in listings:\n",
    "                features = extract_page_features(listing, search_page)\n",
    "                features_list.append(features)\n",
    "\n",
    "            # then go to the second page and scroll through it slowly\n",
    "            next_page.click()\n",
    "\n",
    "            y = 1000\n",
    "\n",
    "            for timer in range(0,50) :\n",
    "                driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "                y += 1000\n",
    "                time.sleep(1)\n",
    "        \n",
    "        else :\n",
    "            print(\"No more pages.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba8ed32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION 2\n",
    "# also didn't work ... \n",
    "def extract_page_listings(search_page) :\n",
    "    \n",
    "    # navigate to the first page\n",
    "    driver.get(search_page)\n",
    "    \n",
    "    while True :\n",
    "    \n",
    "        # scroll through the page to load it\n",
    "        y = 1000\n",
    "\n",
    "        for timer in range(0,50) :\n",
    "            driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "            y += 1000\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "        # parse the html on the page\n",
    "        html = driver.page_source\n",
    "        html_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # grab the listings\n",
    "        listings = html_soup.find_all('div', class_ = 'media-flex__body HitInfo__content')\n",
    "\n",
    "        # extract the features of each listing\n",
    "        features_list = []\n",
    "\n",
    "        for listing in listings:\n",
    "            features = extract_page_features(listing, search_page)\n",
    "            features_list.append(features)\n",
    "\n",
    "        # then go to the second page, if possible\n",
    "        next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n",
    "\n",
    "        if next_page.is_enabled():\n",
    "            next_page.click()\n",
    "\n",
    "        else :\n",
    "            print(\"No more pages.\")\n",
    "            break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2b368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n",
      "<ipython-input-14-0a08ad8cf0a1>:34: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page = driver.find_element_by_xpath('//*[@id=\"Application__resultsViewport\"]/div[1]/section[1]/div[3]/div[2]/div/div[1]/div/nav/ul/li[3]/a')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "extract_page_listings(gardiner_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0945b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8d40f3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f7504be04d44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features_list' is not defined"
     ]
    }
   ],
   "source": [
    "len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebbaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
