{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3fc445",
   "metadata": {},
   "source": [
    "# Airbnb Scrape by Montana Cities\n",
    "\n",
    "I will use Selenium and Beautiful Soup to scrape the Airbnb listings for every town in Montana with a population below 2,500 people. Then I will try to determine if there is a correlation between the number of listings in a given town and: \n",
    "- Median household income\n",
    "- Median home value\n",
    "- Population of select age bands (esp. <18 years old)\n",
    "\n",
    "If my theory holds, higher Airbnb listings will be positively correlated with median household income and median home value, but negatively correlated with population percentage between 18 years old. My theory is that Airbnb allows for greater earning potential for locals, but drives up local home prices by restricting housing supply, and will result in less families moving to those towns because housing will be unaffordable. \n",
    "\n",
    "For this analysis, I am especially interested in the effect of Airbnb on small towns, so I'm not too concerned about locales with more than 300 listings. I will take note of which ones they are, though, and do additional scraping if that location fits my other population criteria (<2,500 residents). (Note: Airbnb does not show more than 300 listings for one area without clicking around the map).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eaf9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import requests               \n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a52e0",
   "metadata": {},
   "source": [
    "## Source List of Montana Cities and Towns\n",
    "\n",
    "The following website has population data sourced from the 2020 Census, where available, else from the 2019 American Community Survey: https://www.montana-demographics.com/cities_by_population.  \n",
    "\n",
    "I read it in below and filter out places with populations greater than 2,500. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289b65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv('Montana.Towns.csv')\n",
    "places.head()\n",
    "places[\"Population\"] = pd.to_numeric(places[\"Population\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154a21a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             City  Population\n",
      "43  East Missoula        2465\n",
      "44         Conrad        2318\n",
      "45      Red Lodge        2257\n",
      "46          Pablo        2138\n",
      "47       Colstrip        2096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_towns = places[places['Population'] <2500] \n",
    "print(small_towns.head())\n",
    "len(small_towns.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1aa187",
   "metadata": {},
   "source": [
    "## Search Airbnb by Place and Scrape Listings\n",
    "\n",
    "Now that I have a list of cities to search on Airbnb, I can use Selenium to go through each place in the list and scrape the listing info. \n",
    "\n",
    "However, there are some issues here. Airbnb is sometimes FAR too generous with the mileage radius is affords locations when it returns search results. For example, when I search listings in Absarokee, MT, Airbnb returns listings all the way from Greycliff to Red Lodge and Park City. If I zoom in twice on the map, I am given listings that appear to be located in Absarokee, proper. \n",
    "\n",
    "However, if I do the same zooming action when I search Gardiner, MT, I wind up with zero listings because it zooms into a mountain range. An additional example: searching for listings in Belfry should be fruitless. There are no listings in the town. However, Airbnb generously draws a circle for Belfry that includes Red Lodge (among other towns), which has many listings. \n",
    "\n",
    "There is no perfect solution to this problem; somtimes no zoom is necessary, sometimes one should zoom in one map level; and other times one should zoom in two map level. In an effort to get the most accurate data, I will scrape Airbnb in two ways: first, by scraping all of the listings that the site returns; second, by scraping all listings returned if I search an area and then zoom in on the map two times. \n",
    "\n",
    "In my final analysis, I will average the two results for a \"final\" listing figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9de7923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the town names, which will be put into the search field\n",
    "towns = small_towns['City'].tolist()\n",
    "len(towns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722e85b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stevensville', 'West Glendive']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a subset to test code on first \n",
    "# tested with a town subset first\n",
    "town_subset = towns[6:8]\n",
    "town_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c8ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.airbnb.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267fd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "town_subset_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153035b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "# test version\n",
    "\n",
    "for town in town_subset :\n",
    "    # open the driver and go to Airbnb's homepage ahead of this loop\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # ID the search field and input the town into it\n",
    "    try :\n",
    "        search_box = driver.find_element(By.CLASS_NAME, \"_1xq16jy\")\n",
    "        search_box.send_keys(f'{town}, MT')\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find search box for {town}\")\n",
    "    \n",
    "     # ID the \"I'm Flexible\" button and click it\n",
    "    try: \n",
    "        flexible_button = driver.find_element(By.CLASS_NAME, \"_9qlt59\")\n",
    "        flexible_button.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find flexible box for {town}\")\n",
    "    \n",
    "     # then click search and provide some time to load the page\n",
    "    try :\n",
    "        search_button = driver.find_element(By.XPATH, '//*[@id=\"search-tabpanel\"]/div/div[5]/div[2]/button/span[1]/span')\n",
    "        search_button.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find search button for {town}\")\n",
    "    \n",
    "    # pull the soup\n",
    "    html = driver.page_source\n",
    "    html_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # grab the number of listings\n",
    "    num_listings = html_soup.find_all('h1', class_ = '_78tyg5')\n",
    "    num_listings_string = []\n",
    "    for x in num_listings:\n",
    "        num_listings_string.append(str(x))\n",
    "    listings = num_listings_string[0].split(\">\")[1].split(\" \")[0]\n",
    "    \n",
    "    # clear out the list for next round\n",
    "    num_listings_string.clear()\n",
    "    \n",
    "    # add to dictionary\n",
    "    town_subset_test[town] = listings\n",
    "    \n",
    "    driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd46eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Stevensville': '133', 'West Glendive': '10'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "town_subset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3699d05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Town</th>\n",
       "      <th>Listings - No Zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stevensville</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West Glendive</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Town Listings - No Zoom\n",
       "0   Stevensville                133\n",
       "1  West Glendive                 10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(list(town_subset_test.items()), columns = ['Town','Listings - No Zoom'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee1fb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "town_listings = {}\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5573aa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't get the listings from Roberts\n",
      "couldn't get the listings from Ballantine\n",
      "couldn't get the listings from Huson a\n",
      "couldn't get the listings from Forest Hill Village\n",
      "couldn't find flexible box for Fort Peck\n",
      "couldn't find search button for Fort Peck\n",
      "couldn't find flexible box for Fox Lake\n",
      "couldn't find search button for Fox Lake\n",
      "couldn't find flexible box for Willow Creek\n",
      "couldn't find search button for Willow Creek\n",
      "couldn't find flexible box for Belfry \n",
      "couldn't find search button for Belfry \n"
     ]
    }
   ],
   "source": [
    "# scrape all towns\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "for town in towns :\n",
    "    # open the driver and go to Airbnb's homepage ahead of this loop\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # ID the search field and input the town into it\n",
    "    try :\n",
    "        search_box = driver.find_element(By.CLASS_NAME, \"_1xq16jy\")\n",
    "        search_box.send_keys(f'{town}, MT')\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find search box for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "     # ID the \"I'm Flexible\" button and click it\n",
    "    try: \n",
    "        flexible_button = driver.find_element(By.CLASS_NAME, \"_9qlt59\")\n",
    "        flexible_button.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find flexible box for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "     # then click search and provide some time to load the page\n",
    "    try :\n",
    "        search_button = driver.find_element(By.XPATH, '//*[@id=\"search-tabpanel\"]/div/div[5]/div[2]/button/span[1]/span')\n",
    "        search_button.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find search button for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "    # pull the soup\n",
    "    html = driver.page_source\n",
    "    html_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # grab the number of listings\n",
    "    num_listings = html_soup.find_all('h1', class_ = '_78tyg5')\n",
    "    num_listings_string = []\n",
    "    for x in num_listings:\n",
    "        num_listings_string.append(str(x))\n",
    "    \n",
    "    try :\n",
    "        listings = num_listings_string[0].split(\">\")[1].split(\" \")[0]\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't get the listings from {town}\")\n",
    "        errors.append(town)\n",
    "        \n",
    "    # clear out the list for next round\n",
    "    num_listings_string.clear()\n",
    "    \n",
    "    # add to dictionary\n",
    "    town_listings[town] = listings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33421614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to data frame\n",
    "\n",
    "noZoom_listings = pd.DataFrame(list(town_listings.items()), columns = ['Town','Listings - No Zoom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aac9a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noZoom_listings.head()\n",
    "len(noZoom_listings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5551bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct scrape of listings when zoomed in twice\n",
    "# note: did a test run first \n",
    "\n",
    "town_listings_zoom = {}\n",
    "town_listings_zoom_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d29ec93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "# test scrape with zoom in on map twice\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "for town in town_subset :\n",
    "    # open the driver and go to Airbnb's homepage ahead of this loop\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # ID the search field and input the town into it\n",
    "    try :\n",
    "        search_box = driver.find_element(By.CLASS_NAME, \"_1xq16jy\")\n",
    "        search_box.send_keys(f'{town}, MT')\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find search box for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "     # ID the \"I'm Flexible\" button and click it\n",
    "    try: \n",
    "        flexible_button = driver.find_element(By.CLASS_NAME, \"_9qlt59\")\n",
    "        flexible_button.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find flexible box for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "     # then click search and provide some time to load the page\n",
    "    try :\n",
    "        search_button = driver.find_element(By.XPATH, '//*[@id=\"search-tabpanel\"]/div/div[5]/div[2]/button/span[1]/span')\n",
    "        search_button.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find search button for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "    # select the \"zoom\" button on the map x2\n",
    "    try :\n",
    "        zoom_button = driver.find_element(By.XPATH, '//*[@id=\"site-content\"]/div[3]/div/div/div/div/div/div/div[3]/div/button[1]')\n",
    "        zoom_button.click()\n",
    "        time.sleep(1)\n",
    "        zoom_button.click()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find the zoom button for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "    # pull the soup\n",
    "    html = driver.page_source\n",
    "    html_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # grab the number of listings\n",
    "    num_listings = html_soup.find_all('h1', class_ = '_78tyg5')\n",
    "    num_listings_string = []\n",
    "    for x in num_listings:\n",
    "        num_listings_string.append(str(x))\n",
    "    \n",
    "    try :\n",
    "        listings = num_listings_string[0].split(\">\")[1].split(\" \")[0]\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't get the listings from {town}\")\n",
    "        errors.append(town)\n",
    "        \n",
    "    # clear out the list for next round\n",
    "    num_listings_string.clear()\n",
    "    \n",
    "    # add to dictionary\n",
    "    town_listings_zoom_test[town] = listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccabe328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Stevensville': '32', 'West Glendive': '0'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of test scrape\n",
    "town_listings_zoom_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95870f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find the zoom button for Colstrip\n",
      "couldn't find the zoom button for Huson a\n",
      "couldn't get the listings from Huson a\n"
     ]
    }
   ],
   "source": [
    "# perform full scrape with zooms\n",
    "# in hindsight, I should have done these scrapes in one step - one after the other. \n",
    "# note to self to edit code accordingly if pulled in the future\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "for town in towns :\n",
    "    # open the driver and go to Airbnb's homepage ahead of this loop\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # ID the search field and input the town into it\n",
    "    try :\n",
    "        search_box = driver.find_element(By.CLASS_NAME, \"_1xq16jy\")\n",
    "        search_box.send_keys(f'{town}, MT')\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find search box for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "     # ID the \"I'm Flexible\" button and click it\n",
    "    try: \n",
    "        flexible_button = driver.find_element(By.CLASS_NAME, \"_9qlt59\")\n",
    "        flexible_button.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find flexible box for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "     # then click search and provide some time to load the page\n",
    "    try :\n",
    "        search_button = driver.find_element(By.XPATH, '//*[@id=\"search-tabpanel\"]/div/div[5]/div[2]/button/span[1]/span')\n",
    "        search_button.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find search button for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "    # select the \"zoom\" button on the map x2\n",
    "    try :\n",
    "        zoom_button = driver.find_element(By.XPATH, '//*[@id=\"site-content\"]/div[3]/div/div/div/div/div/div/div[3]/div/button[1]')\n",
    "        zoom_button.click()\n",
    "        time.sleep(1)\n",
    "        zoom_button.click()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find the zoom button for {town}\")\n",
    "        errors.append(town)\n",
    "    \n",
    "    # pull the soup\n",
    "    html = driver.page_source\n",
    "    html_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # grab the number of listings\n",
    "    num_listings = html_soup.find_all('h1', class_ = '_78tyg5')\n",
    "    num_listings_string = []\n",
    "    for x in num_listings:\n",
    "        num_listings_string.append(str(x))\n",
    "    \n",
    "    try :\n",
    "        listings = num_listings_string[0].split(\">\")[1].split(\" \")[0]\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't get the listings from {town}\")\n",
    "        errors.append(town)\n",
    "        \n",
    "    # clear out the list for next round\n",
    "    num_listings_string.clear()\n",
    "    \n",
    "    # add to dictionary\n",
    "    town_listings_zoom[town] = listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed911d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad520309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to data frame\n",
    "\n",
    "Zoom_listings = pd.DataFrame(list(town_listings_zoom.items()), columns = ['Town','Listings - Zoom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5898f75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zoom_listings.head()\n",
    "len(Zoom_listings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a65544ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv \n",
    "Zoom_listings.to_csv('Zoom_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1819fbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Town</th>\n",
       "      <th>Listings - No Zoom</th>\n",
       "      <th>Listings - Zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East Missoula</td>\n",
       "      <td>281</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conrad</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red Lodge</td>\n",
       "      <td>146</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pablo</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colstrip</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Town Listings - No Zoom Listings - Zoom\n",
       "0  East Missoula                281             180\n",
       "1         Conrad                 28               0\n",
       "2      Red Lodge                146             115\n",
       "3          Pablo                 45              24\n",
       "4       Colstrip                  1               1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two dataframes and include a new column that is the mean of the two listing figures\n",
    "# note: need to change all of the 300+ listings to 300 \n",
    "\n",
    "\n",
    "listings = pd.merge(noZoom_listings, Zoom_listings, on=['Town'])\n",
    "\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afcafe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see which columns are numerical (because I'll need to take the mean)\n",
    "listings.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8c37c419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings = listings.replace('300+',300)\n",
    "listings.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fed27838",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['Listings - No Zoom'] = listings['Listings - No Zoom'].astype(int)\n",
    "listings['Listings - Zoom'] = listings['Listings - Zoom'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bac40083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in a mean column\n",
    "listings['Mean Listings'] = listings[['Listings - No Zoom', 'Listings - Zoom']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "354edbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Town</th>\n",
       "      <th>Listings - No Zoom</th>\n",
       "      <th>Listings - Zoom</th>\n",
       "      <th>Mean Listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East Missoula</td>\n",
       "      <td>281</td>\n",
       "      <td>180</td>\n",
       "      <td>230.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conrad</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red Lodge</td>\n",
       "      <td>146</td>\n",
       "      <td>115</td>\n",
       "      <td>130.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pablo</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colstrip</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Town  Listings - No Zoom  Listings - Zoom  Mean Listings\n",
       "0  East Missoula                 281              180          230.5\n",
       "1         Conrad                  28                0           14.0\n",
       "2      Red Lodge                 146              115          130.5\n",
       "3          Pablo                  45               24           34.5\n",
       "4       Colstrip                   1                1            1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "42971323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "listings.to_csv('listings_by_town.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36dde3",
   "metadata": {},
   "source": [
    "## Appendix: Code to Scrape Airbnb for Listing Features\n",
    "\n",
    "The code in this Appendix goes through every search page result for all small Montana towns and returns a list of features for them - header, # guest, # beds, # baths, etc. \n",
    "\n",
    "This level of information is not needed for the correlation analysis, but is included for potential future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92637f8",
   "metadata": {},
   "source": [
    "### Part 1: Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8bb14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.airbnb.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5336077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "# go to the Airbnb homepage \n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf3eac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the search box\n",
    "search_box = driver.find_element(By.CLASS_NAME, \"_1xq16jy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec915dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write what we be searched\n",
    "search_box.send_keys('Conrad, MT')\n",
    "\n",
    "#Submit the text\n",
    "search_box.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc857d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the \"I'm flexible\" button\n",
    "flexible_button = driver.find_element(By.XPATH, '//*[@id=\"tab--tabs--1\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cca9f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on it\n",
    "flexible_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f752f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then identify the \"search\" button\n",
    "search_button = driver.find_element(By.XPATH, '//*[@id=\"search-tabpanel\"]/div/div[5]/div[2]/button/span[1]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74b8dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and click on it\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09435085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMINDER: add in some time for the page to load before pulling listings    \n",
    "\n",
    "# parse the html and grab the listings\n",
    "# then parse the html on the page\n",
    "html = driver.page_source\n",
    "html_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "listings = html_soup.find_all('div', class_ = 'cuj8fzj ln13ysw dir dir-ltr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb305eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check point - should be 20\n",
    "\n",
    "len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95540593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out how many pages to search\n",
    "    \n",
    "# number of listings\n",
    "num_listings = html_soup.find_all('h1', class_ = '_78tyg5')\n",
    "num_listings_string = []\n",
    "for x in num_listings:\n",
    "    num_listings_string.append(str(x))\n",
    "raw_listings = int(num_listings_string[0].split(\">\")[1].split(\" \")[0])\n",
    "\n",
    "# divide by 20 and round up since there are 20 results per page\n",
    "num_pages = math.ceil(raw_listings /20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4b57a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check point - should be 2\n",
    "num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1592b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "\n",
    "listings_per_page=20\n",
    "\n",
    "current_url = driver.current_url\n",
    "\n",
    "for i in range(num_pages) :\n",
    "    offset = listings_per_page * i\n",
    "    url_pagination = current_url + f'&items_offset={offset}'\n",
    "    url_list.append(url_pagination)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7e4cda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.airbnb.com/s/Conrad--MT/homes?tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&flexible_trip_dates%5B%5D=april&flexible_trip_dates%5B%5D=march&flexible_trip_lengths%5B%5D=weekend_trip&date_picker_type=flexible_dates&source=structured_search_input_header&search_type=filter_change&items_offset=0',\n",
       " 'https://www.airbnb.com/s/Conrad--MT/homes?tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&flexible_trip_dates%5B%5D=april&flexible_trip_dates%5B%5D=march&flexible_trip_lengths%5B%5D=weekend_trip&date_picker_type=flexible_dates&source=structured_search_input_header&search_type=filter_change&items_offset=20']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ea2640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary functions for scraping\n",
    "\n",
    "# this function will extract all the elements in \"search_page\" above from the html \n",
    "\n",
    "def extract_elements(listing_html, params) :\n",
    "     # Find the right tag\n",
    "    if 'class' in params:\n",
    "        elements_found = listing_html.find_all(params['tag'], params['class'])\n",
    "    else:\n",
    "        elements_found = listing_html.find_all(params['tag'])\n",
    "\n",
    "    # Extract the right element\n",
    "    tag_order = params.get('order', 0)\n",
    "    element = elements_found[tag_order]\n",
    "        \n",
    "    # Get text\n",
    "    if 'get' in params:\n",
    "        output = element.get(params['get'])\n",
    "    else:\n",
    "        output = element.get_text()\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# extract all of the elements with this function\n",
    "\n",
    "def extract_page_features(soup, search_items):\n",
    "    # create a dictionary to hold the features\n",
    "    features_dict = {}\n",
    "    \n",
    "    # go through each item of the search block above and try to find it and put it in dict\n",
    "    for feature in search_items :\n",
    "        try:\n",
    "            features_dict[feature] = extract_elements(soup, search_items[feature])\n",
    "            \n",
    "        # if it doesn't exist, place empty in that field\n",
    "        except:\n",
    "            features_dict[feature] = 'empty'\n",
    "    \n",
    "    return features_dict\n",
    "\n",
    "\n",
    "def get_listings(search_page) :\n",
    "    # put the driver ahead of running this function\n",
    "    # driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    \n",
    "    # add in some wait time so the page can load\n",
    "    \n",
    "    driver.get(search_page)\n",
    "    \n",
    "    time.sleep(4)\n",
    "    \n",
    "    # then parse the html on the page\n",
    "    html = driver.page_source\n",
    "    html_soup = BeautifulSoup(html, 'html.parser')\n",
    "    listings = html_soup.find_all('div', class_ = 'cuj8fzj ln13ysw dir dir-ltr')\n",
    "    \n",
    "    # remember to close the driver after running the function\n",
    "    #driver.close()\n",
    "    \n",
    "    return listings\n",
    "\n",
    "def process_search_pages(url_list) :\n",
    "    features_list = []\n",
    "    for page in url_list:\n",
    "        listings = get_listings(page)\n",
    "        for listing in listings:\n",
    "            features = extract_page_features(listing, search_page)\n",
    "            features_list.append(features)\n",
    "\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10ad0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# items to scrape on each page\n",
    "# this is accurate as of 2/21/22 ... if there are empty fields in data frame, fix these tags\n",
    "\n",
    "search_page = {\n",
    "    'name': {'tag':'meta', 'get':'content', 'order':0},\n",
    "    'url': {'tag':'meta', 'get':'content', 'order':2},\n",
    "    'header': {'tag':'div', 'class': 'cuu4odx c1frjvtt dir dir-ltr'},\n",
    "    'guests': {'tag':'span', 'class': 'mp2hv9t dir dir-ltr', 'order':0},\n",
    "    'rooms': {'tag':'span', 'class': 'mp2hv9t dir dir-ltr', 'order':1},\n",
    "    'beds': {'tag':'span', 'class': 'mp2hv9t dir dir-ltr', 'order':2},\n",
    "    'baths': {'tag':'span', 'class': 'mp2hv9t dir dir-ltr', 'order':3},\n",
    "    'price': {'tag':'span', 'class':'a8jt5op dir dir-ltr'},\n",
    "    'rating': {'tag':'span', 'class':'rpz7y38 dir dir-ltr'},\n",
    "    'n_reviews': {'tag':'span', 'class': 'r1xr6rtg dir dir-ltr'},\n",
    "    'superhost': {'tag':'div', 'class': 't1oq1m17 dir dir-ltr'} \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "209dc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the information for each listing in each URL\n",
    "Conrad = process_search_pages(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e34fa59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Blackleaf Creek Ranch Guesthouse',\n",
       " 'url': 'www.airbnb.com/rooms/38430730?adults=1&children=0&infants=0&check_in=2022-04-22&check_out=2022-04-24&previous_page_section_name=1000',\n",
       " 'header': 'Entire cabin in Bynum',\n",
       " 'guests': '4 guests',\n",
       " 'rooms': '1 bedroom',\n",
       " 'beds': '2 beds',\n",
       " 'baths': '1 bath',\n",
       " 'price': '$125 per night',\n",
       " 'rating': '4.88',\n",
       " 'n_reviews': '\\xa0(24 reviews)',\n",
       " 'superhost': 'SUPERHOST'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results\n",
    "Conrad[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6b31a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "818c6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conrad_listings = pd.DataFrame(Conrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce4eff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>header</th>\n",
       "      <th>guests</th>\n",
       "      <th>rooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>superhost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Small Town Charm/Lake Access/Glacier Park</td>\n",
       "      <td>www.airbnb.com/rooms/43789823?adults=1&amp;childre...</td>\n",
       "      <td>Entire residential home in Valier</td>\n",
       "      <td>6 guests</td>\n",
       "      <td>3 bedrooms</td>\n",
       "      <td>4 beds</td>\n",
       "      <td>2 baths</td>\n",
       "      <td>$150 per night</td>\n",
       "      <td>4.94</td>\n",
       "      <td>(31 reviews)</td>\n",
       "      <td>SUPERHOST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blackleaf Creek Ranch Guesthouse</td>\n",
       "      <td>www.airbnb.com/rooms/38430730?adults=1&amp;childre...</td>\n",
       "      <td>Entire cabin in Bynum</td>\n",
       "      <td>4 guests</td>\n",
       "      <td>1 bedroom</td>\n",
       "      <td>2 beds</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>$125 per night</td>\n",
       "      <td>4.88</td>\n",
       "      <td>(24 reviews)</td>\n",
       "      <td>SUPERHOST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEW! Remodeled Choteau Cottage: Ski &amp; Fish Nea...</td>\n",
       "      <td>www.airbnb.com/rooms/46246886?adults=1&amp;childre...</td>\n",
       "      <td>Entire cottage in Choteau</td>\n",
       "      <td>5 guests</td>\n",
       "      <td>2 bedrooms</td>\n",
       "      <td>4 beds</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>$101 per night</td>\n",
       "      <td>4.93</td>\n",
       "      <td>(30 reviews)</td>\n",
       "      <td>SUPERHOST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cut Bank Studio #4 near Glacier National Park!</td>\n",
       "      <td>www.airbnb.com/rooms/19982124?adults=1&amp;childre...</td>\n",
       "      <td>Entire rental unit in Cut Bank</td>\n",
       "      <td>3 guests</td>\n",
       "      <td>Studio</td>\n",
       "      <td>2 beds</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>$89 per night</td>\n",
       "      <td>4.90</td>\n",
       "      <td>(167 reviews)</td>\n",
       "      <td>SUPERHOST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tranquil 4-bedroom Glacier View Getaway</td>\n",
       "      <td>www.airbnb.com/rooms/532553660666635523?adults...</td>\n",
       "      <td>Farm stay in Cut Bank</td>\n",
       "      <td>9 guests</td>\n",
       "      <td>4 bedrooms</td>\n",
       "      <td>5 beds</td>\n",
       "      <td>3 baths</td>\n",
       "      <td>$250 per night</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0          Small Town Charm/Lake Access/Glacier Park   \n",
       "1                   Blackleaf Creek Ranch Guesthouse   \n",
       "2  NEW! Remodeled Choteau Cottage: Ski & Fish Nea...   \n",
       "3     Cut Bank Studio #4 near Glacier National Park!   \n",
       "4            Tranquil 4-bedroom Glacier View Getaway   \n",
       "\n",
       "                                                 url  \\\n",
       "0  www.airbnb.com/rooms/43789823?adults=1&childre...   \n",
       "1  www.airbnb.com/rooms/38430730?adults=1&childre...   \n",
       "2  www.airbnb.com/rooms/46246886?adults=1&childre...   \n",
       "3  www.airbnb.com/rooms/19982124?adults=1&childre...   \n",
       "4  www.airbnb.com/rooms/532553660666635523?adults...   \n",
       "\n",
       "                              header    guests       rooms    beds    baths  \\\n",
       "0  Entire residential home in Valier  6 guests  3 bedrooms  4 beds  2 baths   \n",
       "1              Entire cabin in Bynum  4 guests   1 bedroom  2 beds   1 bath   \n",
       "2          Entire cottage in Choteau  5 guests  2 bedrooms  4 beds   1 bath   \n",
       "3     Entire rental unit in Cut Bank  3 guests      Studio  2 beds   1 bath   \n",
       "4              Farm stay in Cut Bank  9 guests  4 bedrooms  5 beds  3 baths   \n",
       "\n",
       "            price rating       n_reviews  superhost  \n",
       "0  $150 per night   4.94    (31 reviews)  SUPERHOST  \n",
       "1  $125 per night   4.88    (24 reviews)  SUPERHOST  \n",
       "2  $101 per night   4.93    (30 reviews)  SUPERHOST  \n",
       "3   $89 per night   4.90   (167 reviews)  SUPERHOST  \n",
       "4  $250 per night  empty           empty      empty  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check \n",
    "Conrad_listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007af5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last step would be saving to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a880429",
   "metadata": {},
   "source": [
    "### Part 2: Programmatic Scrape\n",
    "\n",
    "Here, I'll try to loop through two towns and scrape information as I did for one town above. Then I will expand to scrape through all 274 towns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24f8b54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "towns = small_towns['City'].tolist()\n",
    "len(towns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83d445c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stevensville', 'West Glendive']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tested with a town subset first\n",
    "town_subset = towns[6:8]\n",
    "town_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82de88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default dictionary to hold the results by city\n",
    "city_listings = defaultdict(dict)\n",
    "test = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d316495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n",
      "<ipython-input-29-be0bc0270e0b>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_box = driver.find_element_by_class_name(\"_1xq16jy\")\n",
      "<ipython-input-29-be0bc0270e0b>:16: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  flexible_button = driver.find_element_by_class_name(\"_9qlt59\")\n",
      "<ipython-input-29-be0bc0270e0b>:21: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_button = driver.find_element_by_xpath('//*[@id=\"search-tabpanel\"]/div/div[5]/div[2]/button/span[1]/span')\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/austinsmith/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "# testing out on two towns first ... \n",
    "\n",
    "for town in town_subset :\n",
    "    # open the driver and go to Airbnb's homepage ahead of this loop\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # ID the search field and input the town into it\n",
    "    try :\n",
    "        search_box = driver.find_element(By.CLASS_NAME, \"_1xq16jy\")\n",
    "        search_box.send_keys(f'{town}, MT')\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print(f\"couldn't find search field for {town}\")\n",
    "    \n",
    "     # ID the \"I'm Flexible\" button and click it\n",
    "    try :\n",
    "        flexible_button = driver.find_element(By.CLASS_NAME, \"_9qlt59\")\n",
    "        flexible_button.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print(f\"couldn't find flexible button for {town}\")\n",
    "    \n",
    "     # then click search and provide some time to load the page\n",
    "    try:\n",
    "        search_button = driver.find_element(By.XPATH, '//*[@id=\"search-tabpanel\"]/div/div[5]/div[2]/button/span[1]/span')\n",
    "        search_button.click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        print(f\"couldn't find search button for {town}\")\n",
    "    \n",
    "    # figure out how many pages to search\n",
    "    html = driver.page_source\n",
    "    html_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # number of listings\n",
    "    num_listings = html_soup.find_all('h1', class_ = '_78tyg5')\n",
    "    num_listings_string = []\n",
    "    for x in num_listings:\n",
    "        num_listings_string.append(str(x))\n",
    "    try :\n",
    "        raw_listings = int(num_listings_string[0].split(\">\")[1].split(\" \")[0])\n",
    "    except :\n",
    "        print(f\"there's something weird with pages in {town}\")\n",
    "    \n",
    "    # clear out the list for next round\n",
    "    num_listings_string.clear()\n",
    "    \n",
    "    # divide by 20 and round up since there are 20 results per page\n",
    "    num_pages = math.ceil(raw_listings /20)\n",
    "    \n",
    "    # grab the urls to search for each page of results\n",
    "    url_list = []\n",
    "    listings_per_page=20\n",
    "    \n",
    "    current_url = driver.current_url\n",
    "\n",
    "    for i in range(num_pages) :\n",
    "        offset = listings_per_page * i\n",
    "        url_pagination = current_url + f'&items_offset={offset}'\n",
    "        url_list.append(url_pagination)\n",
    "    \n",
    "    # scrape each page and add the results to the default dictionary\n",
    "    if len(url_list) == num_pages :\n",
    "        test[town] = process_search_pages(url_list)\n",
    "    else :\n",
    "        print(\"Didn't get the correct # of pages.\")\n",
    "    \n",
    "    # clear out URL list\n",
    "    url_list.clear()\n",
    "    \n",
    "    # then quit that webpage before starting on the next town\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b7ab29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check point - should be 133\n",
    "len(test['Stevensville'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5eb6e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check poing - should be 10\n",
    "len(test['West Glendive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand to all towns \n",
    "# not run because this takes forever\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "for town in towns :\n",
    "    # open the driver and go to Airbnb's homepage ahead of this loop\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # ID the search field and input the town into it\n",
    "    try :\n",
    "        search_box = driver.find_element(By.CLASS_NAME, \"_1xq16jy\")\n",
    "        search_box.send_keys(f'{town}, MT')\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find the search box for {town}\")\n",
    "    \n",
    "     # ID the \"I'm Flexible\" button and click it\n",
    "    try :\n",
    "        flexible_button = driver.find_element(By.CLASS_NAME, \"_9qlt59\")\n",
    "        flexible_button.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find the flexible button for {town}\")\n",
    "    \n",
    "     # then click search and provide some time to load the page\n",
    "    try :\n",
    "        search_button = driver.find_element(By.XPATH, '//*[@id=\"search-tabpanel\"]/div/div[5]/div[2]/button/span[1]/span')\n",
    "        search_button.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    except :\n",
    "        print(f\"couldn't find the search button for {town}\")\n",
    "    \n",
    "    # figure out how many pages to search\n",
    "    html = driver.page_source\n",
    "    html_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # number of listings\n",
    "    num_listings = html_soup.find_all('h1', class_ = '_78tyg5')\n",
    "    num_listings_string = []\n",
    "    for x in num_listings:\n",
    "        num_listings_string.append(str(x))\n",
    "    \n",
    "    # the code below accounts for the possibility that there may be \"300+\" listings\n",
    "    try :\n",
    "        raw_listings = (num_listings_string[0].split(\">\")[1].split(\" \")[0])\n",
    "    except :\n",
    "        print(f\"couldn't get the page #s for {town}\")\n",
    "\n",
    "    if raw_listings == '300+' :\n",
    "        num_listings = int(raw_listings[:-1])\n",
    "    else :\n",
    "        num_listings = int(raw_listings)\n",
    "\n",
    "    # clear out the list for next round\n",
    "    num_listings_string.clear()\n",
    "    \n",
    "    # divide by 20 and round up since there are 20 results per page\n",
    "    num_pages = math.ceil(num_listings /20)\n",
    "    \n",
    "    # grab the urls to search for each page of results\n",
    "    url_list = []\n",
    "    listings_per_page=20\n",
    "    \n",
    "    current_url = driver.current_url\n",
    "\n",
    "    for i in range(num_pages) :\n",
    "        offset = listings_per_page * i\n",
    "        url_pagination = current_url + f'&items_offset={offset}'\n",
    "        url_list.append(url_pagination)\n",
    "    \n",
    "    # scrape each page and add the results to the default dictionary\n",
    "    if len(url_list) == num_pages :\n",
    "        city_listings[town] = process_search_pages(url_list)\n",
    "    else :\n",
    "        print(\"Didn't get the correct # of pages.\")\n",
    "    \n",
    "    # clear out URL list\n",
    "    url_list.clear()\n",
    "    \n",
    "    # then quit that webpage before starting on the next town\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11c7f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590faa16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
