{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e5cb91",
   "metadata": {},
   "source": [
    "# Airbnb Web Scrape\n",
    "\n",
    "My goal is to scrape the details page of all of the listings in and around Gardiner, MT and West Yellowstone, MT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c37fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for Beautiful Soup\n",
    "\n",
    "import requests               # To get the pages\n",
    "from bs4 import BeautifulSoup # and to process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e946adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for Selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selectorlib import Extractor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6efc18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the Gardiner URL first\n",
    "\n",
    "url_gardiner = 'https://www.airbnb.com/s/Gardiner--MT/homes?adults=2&place_id=ChIJ0fUtVMO3T1MRH5WCc2sS2a0&tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&query=Gardiner%2C%20MT&date_picker_type=flexible_dates&flexible_trip_lengths%5B%5D=one_week&source=structured_search_input_header&search_type=filter_change'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5aa5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url_gardiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b5cb9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f917a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I have tried scarping in a few formats: lxml, html, and html.parser\n",
    "\n",
    "soup = BeautifulSoup(response.content,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec503fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867914b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the element I want it to find, which includes the pertinent\n",
    "# listing details. It's on the website when I inspect the element, \n",
    "# but it doesn't exist in the soup object created above and I'm not sure why\n",
    "\n",
    "soup.select('[itemprop=itemListElement]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "779c8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also tried pulling just the basic top-level listings, which are\n",
    "# identified with this class: \"_8ssblpx\"\n",
    "# there should be 20 of them (that's how many listings airbnb shows per page)\n",
    "\n",
    "listings = soup.findAll('div', {'class': '_8ssblpx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c1174d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e431b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9422780",
   "metadata": {},
   "source": [
    "## Notes below for future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a97894d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract HTML and put it into a Beautiful Soup object:\n",
    "\n",
    "def scrape_page(url):\n",
    "    answer = requests.get(url)\n",
    "    content = answer.content\n",
    "    soup = BeautifulSoup(content, features = 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e4bfdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function grabs all of the listings on a given search page\n",
    "\n",
    "def extract_listing(url):\n",
    "    page_soup = scrape_page(url)\n",
    "    listings_title = page_soup.find_all('div',{'class' : 'c1tbui0o ltlgcp dir dir-ltr'})\n",
    "    \n",
    "    return listings_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7610b278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_listing(url_gardiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that holds the information we want from each listing\n",
    "\n",
    "rules_search_page = {\n",
    "    'url': {'tag': 'a', 'get': 'href'},\n",
    "    'name': {'tag': 'span', 'class': 't16jmdcf t5nhi1p t174r01n dir dir-ltr', 'get': 'style'},\n",
    "    'guests': {'tag': 'span', 'class': 'mvk3iwl dir dir-ltr'},\n",
    "    # question: how to tell the classes apart for guests, beds, and baths? \n",
    "    #'beds' : {'tag': 'div', 'class': ''},\n",
    "    #'baths': {'tag': 'div', 'class': ''},\n",
    "    'price': {'tag': 'span', 'class': '_tyxjp1'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f1ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c4c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2562750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all of the data elements that are included on the search page \n",
    "\n",
    "def extract_element_data(soup, params):\n",
    "    \n",
    "    # 1. Find the right tag\n",
    "    if 'class' in params:\n",
    "        elements_found = soup.find_all(params['tag'], params['class'])\n",
    "    else:\n",
    "        elements_found = soup.find_all(params['tag'])\n",
    "        \n",
    "    # 2. Extract text from these tags\n",
    "    if 'get' in params:\n",
    "        element_texts = [el.get(params['get']) for el in elements_found]\n",
    "    else:\n",
    "        element_texts = [el.get_text() for el in elements_found]\n",
    "        \n",
    "    # 3. Select a particular text or concatenate all of them\n",
    "    tag_order = params.get('order', 0)\n",
    "    if tag_order == -1:\n",
    "        output = '**__**'.join(element_texts)\n",
    "    else:\n",
    "        output = element_texts[tag_order]\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb11181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d199b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392d14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "\n",
    "for listing in listing_soups :\n",
    "    features_dict = {}\n",
    "    for feature in rules_search_page :\n",
    "        features_dict[feature] = extract_element_data(listing, rules_search_page[feature])\n",
    "        features_list.append(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d3ce84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf37ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
